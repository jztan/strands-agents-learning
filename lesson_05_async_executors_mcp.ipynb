{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: Async Streaming, Executors, Multi-modal & MCP\n",
    "\n",
    "Master async operations, streaming, tool execution strategies, multi-modal content, and external tool integration:\n",
    "\n",
    "- ‚úÖ Async tool definition with `async def` and `await`\n",
    "- ‚úÖ Streaming progress updates with `yield` in async tools\n",
    "- ‚úÖ Using `agent.stream_async()` for real-time responses\n",
    "- ‚úÖ ConcurrentToolExecutor for parallel tool execution (default)\n",
    "- ‚úÖ SequentialToolExecutor for ordered tool execution\n",
    "- ‚úÖ Multi-modal content (images, PDFs, documents)\n",
    "- ‚úÖ Model Context Protocol (MCP) for external tool integration\n",
    "- ‚úÖ Combining MCP tools with custom Python tools\n",
    "\n",
    "**Estimated time:** 5-6 hours\n",
    "\n",
    "**What you'll build:** Streaming tools, executor comparisons, multi-modal examples, and MCP integrations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary modules and configure the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands.tools.executors import ConcurrentToolExecutor, SequentialToolExecutor\n",
    "\n",
    "from lesson_utils import (\n",
    "    load_environment,\n",
    "    create_working_model,\n",
    "    check_api_keys,\n",
    "    print_troubleshooting,\n",
    ")\n",
    "\n",
    "# Load environment and check API keys\n",
    "load_environment()\n",
    "check_api_keys()\n",
    "\n",
    "print(\"üéØ Lesson 5: Async Streaming, Executors & Multi-modal\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Async Tools with Streaming Progress\n",
    "\n",
    "Async tools can `yield` intermediate results to provide real-time progress updates. Each yielded value becomes a streaming event that you can consume with `agent.stream_async()`.\n",
    "\n",
    "**Reference:** [Python Tools - Tool Streaming](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/python-tools/#tool-streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define async tools with yield for streaming progress\n",
    "\n",
    "@tool\n",
    "async def process_dataset(records: int) -> str:\n",
    "    \"\"\"Process records with progress updates.\"\"\"\n",
    "    start = datetime.now()\n",
    "\n",
    "    for i in range(1, records + 1):\n",
    "        await asyncio.sleep(0.1)  # Simulate processing time\n",
    "        if i % 10 == 0:\n",
    "            elapsed = (datetime.now() - start).total_seconds()\n",
    "            yield f\"Processed {i}/{records} records in {elapsed:.1f}s\"\n",
    "\n",
    "    total_time = (datetime.now() - start).total_seconds()\n",
    "    yield f\"‚úì Completed {records} records in {total_time:.1f}s\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def download_file(url: str, size_mb: int = 10) -> str:\n",
    "    \"\"\"Simulate downloading a file with progress updates.\"\"\"\n",
    "    chunks = 10\n",
    "    chunk_size = size_mb / chunks\n",
    "\n",
    "    yield f\"Starting download: {url} ({size_mb}MB)\"\n",
    "\n",
    "    for i in range(1, chunks + 1):\n",
    "        await asyncio.sleep(0.2)  # Simulate download time\n",
    "        progress = (i / chunks) * 100\n",
    "        downloaded = chunk_size * i\n",
    "        yield f\"Downloaded {downloaded:.1f}MB / {size_mb}MB ({progress:.0f}%)\"\n",
    "\n",
    "    yield f\"‚úì Download complete: {url}\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Async streaming tools created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    # Create agent with async streaming tools\n",
    "    agent = Agent(\n",
    "        model=model,\n",
    "        tools=[process_dataset, download_file],\n",
    "        system_prompt=\"You are a helpful assistant with data processing capabilities.\",\n",
    "    )\n",
    "\n",
    "    print(\"Streaming progress from async tools...\\n\")\n",
    "\n",
    "    async def demo_streaming():\n",
    "        async for event in agent.stream_async(\"Process 30 records\"):\n",
    "            # Check for tool stream events (progress updates)\n",
    "            if tool_stream := event.get(\"tool_stream_event\"):\n",
    "                if update := tool_stream.get(\"data\"):\n",
    "                    print(f\"üìä Progress: {update}\")\n",
    "\n",
    "            # Check for final text response\n",
    "            if \"data\" in event and not event.get(\"tool_stream_event\"):\n",
    "                print(f\"ü§ñ Agent: {event['data']}\", end=\"\")\n",
    "\n",
    "    await demo_streaming()\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: ConcurrentToolExecutor (Parallel Execution)\n",
    "\n",
    "`ConcurrentToolExecutor` is the default executor. It executes multiple tools in parallel when the LLM requests multiple tools in a single response.\n",
    "\n",
    "**Reference:** [Tool Executors](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/executors/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools that simulate API calls\n",
    "\n",
    "@tool\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather forecast for a city.\"\"\"\n",
    "    await asyncio.sleep(1.0)  # Simulate API call\n",
    "    return f\"Weather in {city}: Sunny, 72¬∞F\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def get_time(city: str) -> str:\n",
    "    \"\"\"Get current time in a city.\"\"\"\n",
    "    await asyncio.sleep(1.0)  # Simulate API call\n",
    "    return f\"Time in {city}: 2:30 PM\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def get_population(city: str) -> str:\n",
    "    \"\"\"Get population of a city.\"\"\"\n",
    "    await asyncio.sleep(1.0)  # Simulate database query\n",
    "    return f\"Population of {city}: ~1.5 million\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ API simulation tools created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    # ConcurrentToolExecutor is the default\n",
    "    agent = Agent(\n",
    "        model=model,\n",
    "        tool_executor=ConcurrentToolExecutor(),\n",
    "        tools=[get_weather, get_time, get_population],\n",
    "        system_prompt=\"Use tools to answer user questions about cities.\",\n",
    "    )\n",
    "\n",
    "    print(\"Testing ConcurrentToolExecutor (tools run in parallel)...\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = await agent.invoke_async(\n",
    "        \"What's the weather, time, and population in Seattle?\"\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {response}\")\n",
    "    print(f\"\\n‚ö° Total time: {elapsed:.2f}s\")\n",
    "    print(\"üí° With concurrent execution, 3 tools (each taking 1s) complete in ~1s!\")\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: SequentialToolExecutor (Ordered Execution)\n",
    "\n",
    "`SequentialToolExecutor` executes tools one after another in the order specified by the LLM. This is useful for dependent operations where one tool's output is needed by the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for dependent operations\n",
    "\n",
    "@tool\n",
    "async def take_screenshot(filename: str) -> str:\n",
    "    \"\"\"Take a screenshot and save to file.\"\"\"\n",
    "    await asyncio.sleep(0.5)  # Simulate screenshot capture\n",
    "    return f\"Screenshot saved to {filename}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def compress_file(filename: str) -> str:\n",
    "    \"\"\"Compress a file to save space.\"\"\"\n",
    "    await asyncio.sleep(0.5)  # Simulate compression\n",
    "    compressed = filename.replace(\".png\", \".zip\")\n",
    "    return f\"Compressed {filename} to {compressed}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def send_email(recipient: str, attachment: str) -> str:\n",
    "    \"\"\"Send an email with an attachment.\"\"\"\n",
    "    await asyncio.sleep(0.5)  # Simulate email sending\n",
    "    return f\"Email sent to {recipient} with attachment: {attachment}\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Workflow tools created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    # Use SequentialToolExecutor for dependent operations\n",
    "    agent = Agent(\n",
    "        model=model,\n",
    "        tool_executor=SequentialToolExecutor(),\n",
    "        tools=[take_screenshot, compress_file, send_email],\n",
    "        system_prompt=\"Execute tasks in the correct order for dependent operations.\",\n",
    "    )\n",
    "\n",
    "    print(\"Testing SequentialToolExecutor (tools run in order)...\")\n",
    "    print(\"Task: Take screenshot ‚Üí Compress ‚Üí Email\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = await agent.invoke_async(\n",
    "        \"Take a screenshot named report.png, compress it, \"\n",
    "        \"then email the compressed file to boss@company.com\"\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {response}\")\n",
    "    print(f\"\\n‚è±Ô∏è  Total time: {elapsed:.2f}s\")\n",
    "    print(\"üí° Operations executed in the correct order!\")\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Performance Comparison\n",
    "\n",
    "Let's compare the performance difference between concurrent and sequential execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def fetch_data(source: str) -> str:\n",
    "    \"\"\"Fetch data from a source (simulated).\"\"\"\n",
    "    await asyncio.sleep(1.0)  # Simulate network delay\n",
    "    return f\"Data from {source}: [sample data]\"\n",
    "\n",
    "\n",
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    # Test with ConcurrentToolExecutor\n",
    "    print(\"1. Testing ConcurrentToolExecutor:\")\n",
    "    concurrent_agent = Agent(\n",
    "        model=model,\n",
    "        tool_executor=ConcurrentToolExecutor(),\n",
    "        tools=[fetch_data],\n",
    "        system_prompt=\"Fetch data from multiple sources.\",\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    await concurrent_agent.invoke_async(\"Fetch data from API-A, API-B, and API-C\")\n",
    "    concurrent_time = time.time() - start\n",
    "    print(f\"   ‚ö° Concurrent time: {concurrent_time:.2f}s\")\n",
    "\n",
    "    # Test with SequentialToolExecutor\n",
    "    print(\"\\n2. Testing SequentialToolExecutor:\")\n",
    "    sequential_agent = Agent(\n",
    "        model=model,\n",
    "        tool_executor=SequentialToolExecutor(),\n",
    "        tools=[fetch_data],\n",
    "        system_prompt=\"Fetch data from multiple sources.\",\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    await sequential_agent.invoke_async(\"Fetch data from API-A, API-B, and API-C\")\n",
    "    sequential_time = time.time() - start\n",
    "    print(f\"   ‚è±Ô∏è  Sequential time: {sequential_time:.2f}s\")\n",
    "\n",
    "    # Show comparison\n",
    "    print(\"\\n3. Performance Summary:\")\n",
    "    print(f\"   Concurrent: {concurrent_time:.2f}s\")\n",
    "    print(f\"   Sequential: {sequential_time:.2f}s\")\n",
    "    speedup = sequential_time / concurrent_time if concurrent_time > 0 else 1\n",
    "    print(f\"   Speedup: {speedup:.2f}x faster with concurrent execution!\")\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Multi-modal Content\n",
    "\n",
    "Agents can process multi-modal content including images and PDFs. This enables visual understanding and document analysis.\n",
    "\n",
    "**Reference:** [Multi-modal Example](https://strandsagents.com/latest/documentation/docs/examples/python/multimodal/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-modal works with any vision model (OpenAI, Anthropic, etc.)\n",
    "# We pass images directly in messages using Bedrock Converse format\n",
    "\n",
    "import os\n",
    "\n",
    "# Create sample receipt\n",
    "def create_sample_receipt():\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    \n",
    "    width, height = 400, 600\n",
    "    img = Image.new('RGB', (width, height), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    try:\n",
    "        font_large = ImageFont.truetype(\"Arial.ttf\", 24)\n",
    "        font_medium = ImageFont.truetype(\"Arial.ttf\", 18)\n",
    "        font_small = ImageFont.truetype(\"Arial.ttf\", 14)\n",
    "    except IOError:\n",
    "        font_large = ImageFont.load_default()\n",
    "        font_medium = ImageFont.load_default()\n",
    "        font_small = ImageFont.load_default()\n",
    "    \n",
    "    # Draw receipt (simplified)\n",
    "    y = 20\n",
    "    draw.text((width//2-70, y), \"ACME GROCERY\", fill='black', font=font_large)\n",
    "    y += 40\n",
    "    draw.text((width//2-60, y), \"123 Main St\", fill='black', font=font_small)\n",
    "    y += 40\n",
    "    draw.line([(20, y), (width-20, y)], fill='black', width=2)\n",
    "    y += 20\n",
    "    draw.text((20, y), \"Receipt #: 2025-001234\", fill='black', font=font_small)\n",
    "    y += 25\n",
    "    draw.text((20, y), \"Date: Oct 11, 2025\", fill='black', font=font_small)\n",
    "    y += 40\n",
    "    \n",
    "    items = [\n",
    "        (\"Apples (2 lbs)\", \"$5.99\"),\n",
    "        (\"Bread\", \"$3.49\"),\n",
    "        (\"Eggs (12)\", \"$4.99\"),\n",
    "        (\"Milk\", \"$4.29\"),\n",
    "        (\"Salmon\", \"$12.99\"),\n",
    "        (\"Greens\", \"$3.49\"),\n",
    "    ]\n",
    "    for item, price in items:\n",
    "        draw.text((20, y), item, fill='black', font=font_small)\n",
    "        draw.text((width-80, y), price, fill='black', font=font_small)\n",
    "        y += 22\n",
    "    \n",
    "    y += 10\n",
    "    draw.line([(20, y), (width-20, y)], fill='black', width=1)\n",
    "    y += 20\n",
    "    draw.text((20, y), \"Subtotal:\", fill='black', font=font_medium)\n",
    "    draw.text((width-85, y), \"$35.24\", fill='black', font=font_medium)\n",
    "    y += 25\n",
    "    draw.text((20, y), \"Tax:\", fill='black', font=font_medium)\n",
    "    draw.text((width-85, y), \"$3.00\", fill='black', font=font_medium)\n",
    "    y += 25\n",
    "    draw.line([(20, y), (width-20, y)], fill='black', width=2)\n",
    "    y += 20\n",
    "    draw.text((20, y), \"TOTAL:\", fill='black', font=font_large)\n",
    "    draw.text((width-90, y), \"$38.24\", fill='black', font=font_large)\n",
    "    \n",
    "    filename = 'sample_receipt.png'\n",
    "    img.save(filename)\n",
    "    return filename\n",
    "\n",
    "print(\"üì∏ Creating sample receipt...\")\n",
    "receipt_path = create_sample_receipt()\n",
    "print(f\"‚úì Created: {receipt_path}\\n\")\n",
    "\n",
    "# Read image as bytes\n",
    "with open(receipt_path, 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    print(\"Using provider-agnostic multi-modal approach\\n\")\n",
    "    \n",
    "    # Demo 1: Document Analyzer (works with any vision model)\n",
    "    print(\"1. Document Analyzer:\")\n",
    "    analyzer = Agent(\n",
    "        model=model,\n",
    "        system_prompt=\"Analyze images and extract all visible text and key information.\"\n",
    "    )\n",
    "    \n",
    "    # Pass image directly in message (Bedrock Converse format)\n",
    "    message = [\n",
    "        {\"text\": \"Analyze this receipt image and extract key information:\"},\n",
    "        {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": image_bytes}}}\n",
    "    ]\n",
    "    \n",
    "    response = await analyzer.invoke_async(message)\n",
    "    print(f\"üìÑ Analysis:\\n{response}\\n\")\n",
    "    \n",
    "    # Demo 2: Receipt Extractor\n",
    "    print(\"2. Receipt Extractor:\")\n",
    "    extractor = Agent(\n",
    "        model=model,\n",
    "        system_prompt=\"Extract financial data: store, date, line items, totals.\"\n",
    "    )\n",
    "    \n",
    "    message = [\n",
    "        {\"text\": \"Extract all financial data from this receipt:\"},\n",
    "        {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": image_bytes}}}\n",
    "    ]\n",
    "    \n",
    "    response = await extractor.invoke_async(message)\n",
    "    print(f\"üí∞ Data:\\n{response}\\n\")\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(receipt_path)\n",
    "    \n",
    "    print(\"üí° Key Takeaways:\")\n",
    "    print(\"‚úì Images passed directly in messages (provider-agnostic)\")\n",
    "    print(\"‚úì Works with OpenAI, Anthropic, and other vision models\")\n",
    "    print(\"‚úì Bedrock Converse format: {'image': {'format': 'png', ...}}\")\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: PDF Document Processing\n",
    "print(\"\\n3. PDF Document Processing:\")\n",
    "\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.pdfgen import canvas\n",
    "    from reportlab.lib.units import inch\n",
    "    \n",
    "    # Create sample PDF\n",
    "    pdf_path = \"sample_report.pdf\"\n",
    "    c = canvas.Canvas(pdf_path, pagesize=letter)\n",
    "    width, height = letter\n",
    "    \n",
    "    # Add title\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(1 * inch, height - 1 * inch, \"Quarterly Sales Report - Q4 2024\")\n",
    "    \n",
    "    # Add content\n",
    "    c.setFont(\"Helvetica\", 12)\n",
    "    y = height - 1.5 * inch\n",
    "    lines = [\n",
    "        \"Executive Summary:\",\n",
    "        \"\",\n",
    "        \"‚Ä¢ Total Revenue: $2,450,000\",\n",
    "        \"‚Ä¢ Growth Rate: +23% YoY\",\n",
    "        \"‚Ä¢ Top Product: Enterprise Platform (45% of sales)\",\n",
    "        \"‚Ä¢ Customer Acquisition: 150 new clients\",\n",
    "        \"‚Ä¢ Customer Retention: 94%\",\n",
    "        \"\",\n",
    "        \"Regional Performance:\",\n",
    "        \"‚Ä¢ North America: $1,200,000 (49%)\",\n",
    "        \"‚Ä¢ Europe: $800,000 (33%)\",\n",
    "        \"‚Ä¢ Asia Pacific: $450,000 (18%)\",\n",
    "        \"\",\n",
    "        \"Key Initiatives for Q1 2025:\",\n",
    "        \"1. Launch mobile application\",\n",
    "        \"2. Expand European operations\",\n",
    "        \"3. Enhance customer support infrastructure\",\n",
    "    ]\n",
    "    \n",
    "    for line in lines:\n",
    "        c.drawString(1 * inch, y, line)\n",
    "        y -= 0.25 * inch\n",
    "    \n",
    "    c.save()\n",
    "    print(f\"‚úì Created PDF: {pdf_path}\\n\")\n",
    "    \n",
    "    # Read PDF as bytes\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        pdf_bytes = f.read()\n",
    "    \n",
    "    # Analyze PDF with agent\n",
    "    pdf_analyzer = Agent(\n",
    "        model=model,\n",
    "        system_prompt=\"You are a business document analyst. \"\n",
    "        \"Analyze PDF reports and summarize key metrics and insights.\"\n",
    "    )\n",
    "    \n",
    "    # Pass PDF in message\n",
    "    message = [\n",
    "        {\"text\": \"Analyze this quarterly report and summarize the key findings:\"},\n",
    "        {\"document\": {\"format\": \"pdf\", \"name\": pdf_path, \"source\": {\"bytes\": pdf_bytes}}},\n",
    "    ]\n",
    "    \n",
    "    response = await pdf_analyzer.invoke_async(message)\n",
    "    print(f\"üìä PDF Analysis:\\n{response}\\n\")\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(pdf_path)\n",
    "    print(\"‚úì PDF cleaned up\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  reportlab not installed - skipping PDF example\")\n",
    "    print(\"   Install with: uv sync --dev\")\n",
    "    print(\"   (reportlab is in optional dev dependencies)\")\n",
    "    \n",
    "print(\"\\nüí° Multi-modal Key Takeaways:\")\n",
    "print(\"‚úì Images: {'image': {'format': 'png', 'source': {'bytes': ...}}}\")\n",
    "print(\"‚úì PDFs: {'document': {'format': 'pdf', 'source': {'bytes': ...}}}\")\n",
    "print(\"‚úì Works with OpenAI, Anthropic, and other vision models\")\n",
    "print(\"‚úì Provider-agnostic Bedrock Converse format\")\n",
    "print(\"‚úì Enables OCR, document analysis, visual QA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Model Context Protocol (MCP) Integration\n",
    "\n",
    "The Model Context Protocol (MCP) enables agents to use external tools provided by MCP servers. This extends agent capabilities beyond custom Python tools to include documentation servers, APIs, and other external services.\n",
    "\n",
    "**Important:** All MCP operations must be inside a context manager (`with mcp_client:`).\n",
    "\n",
    "**Reference:** [MCP Tools](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/mcp-tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example A: AWS Documentation MCP Server (Optional)\n",
    "# MCP enables access to external documentation and APIs\n",
    "\n",
    "try:\n",
    "    from mcp import stdio_client, StdioServerParameters\n",
    "    from strands.tools.mcp import MCPClient\n",
    "    \n",
    "    print(\"Example A: AWS Documentation MCP Server\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Create MCP client for AWS docs (stdio transport)\n",
    "    aws_docs_client = MCPClient(\n",
    "        lambda: stdio_client(\n",
    "            StdioServerParameters(\n",
    "                command=\"uvx\",\n",
    "                args=[\"awslabs.aws-documentation-mcp-server@latest\"]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(\"Connecting to AWS documentation server via stdio...\")\n",
    "    with aws_docs_client:\n",
    "        # Discover available MCP tools\n",
    "        mcp_tools = aws_docs_client.list_tools_sync()\n",
    "        print(f\"‚úì Connected! Found {len(mcp_tools)} AWS documentation tools\\n\")\n",
    "        \n",
    "        # Create agent with MCP tools\n",
    "        model = create_working_model()\n",
    "        agent = Agent(\n",
    "            model=model,\n",
    "            tools=mcp_tools,\n",
    "            system_prompt=\"You help with AWS services. \"\n",
    "            \"Use documentation tools for accurate information.\",\n",
    "        )\n",
    "        \n",
    "        # Agent will automatically select and use MCP tools\n",
    "        response = agent(\"What is AWS Lambda and when should I use it?\")\n",
    "        print(f\"ü§ñ Agent: {response}\\n\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  MCP packages not available: {e}\")\n",
    "    print(\"   Install with: uv sync\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  AWS MCP server not available: {e}\")\n",
    "    print(\"   Note: This is optional - MCP servers require external packages\")\n",
    "    print(\"   Install with: uvx install awslabs.aws-documentation-mcp-server\")\n",
    "    print(\"   Continuing without MCP example...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example B: Combining MCP with Custom Async Tools\n",
    "# Demonstrates hybrid agents with both MCP and Python tools\n",
    "\n",
    "try:\n",
    "    print(\"\\nExample B: Hybrid Agent (MCP + Custom Async Tools)\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Create MCP client\n",
    "    aws_docs_client = MCPClient(\n",
    "        lambda: stdio_client(\n",
    "            StdioServerParameters(\n",
    "                command=\"uvx\",\n",
    "                args=[\"awslabs.aws-documentation-mcp-server@latest\"]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Define custom async tool\n",
    "    @tool\n",
    "    async def process_records(count: int) -> str:\n",
    "        \"\"\"Process records with progress.\"\"\"\n",
    "        await asyncio.sleep(0.5)\n",
    "        return f\"Processed {count} records\"\n",
    "    \n",
    "    print(\"Combining external MCP tools with custom async tools...\")\n",
    "    with aws_docs_client:\n",
    "        mcp_tools = aws_docs_client.list_tools_sync()\n",
    "        \n",
    "        # Combine MCP tools + custom async tools\n",
    "        all_tools = mcp_tools + [process_records]\n",
    "        \n",
    "        model = create_working_model()\n",
    "        agent = Agent(\n",
    "            model=model,\n",
    "            tools=all_tools,\n",
    "            system_prompt=\"You can both lookup AWS documentation and \"\n",
    "            \"process records. Use the right tool for each task.\",\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Agent has {len(all_tools)} tools \"\n",
    "              f\"({len(mcp_tools)} MCP + 1 custom)\\n\")\n",
    "        \n",
    "        response = agent(\"Look up AWS DynamoDB, then process 50 records\")\n",
    "        print(f\"ü§ñ Agent: {response}\\n\")\n",
    "        \n",
    "    print(\"üí° MCP Key Concepts:\")\n",
    "    print(\"   1. Context managers required: with mcp_client:\")\n",
    "    print(\"   2. Tools discovered via list_tools_sync()\")\n",
    "    print(\"   3. MCP tools work alongside custom Python tools\")\n",
    "    print(\"   4. stdio transport runs servers as subprocesses (uvx)\")\n",
    "    print(\"   5. Multiple servers can be combined together\")\n",
    "    print(\"   6. SSE and HTTP transports also available\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Combined tools demo skipped: {e}\")\n",
    "    print(\"   MCP is optional - lesson continues without it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Now it's your turn! Try these experiments:\n",
    "\n",
    "### Exercises:\n",
    "1. **Large dataset processing** - Process 100 records and watch the streaming progress\n",
    "2. **Variable delays** - Create tools with different delays (0.5s, 1s, 2s) and compare executors\n",
    "3. **Data pipeline** - Build a multi-step pipeline with dependent operations\n",
    "4. **Parallel API calls** - Simulate calling 5 different APIs concurrently\n",
    "5. **Real images** - Use different receipt/invoice images with the multi-modal approach\n",
    "6. **Multiple images** - Pass multiple images in one message for comparison\n",
    "7. **Document classification** - Build a classifier that categorizes document types\n",
    "8. **AWS Documentation MCP** (Optional) - Integrate AWS MCP server for AWS technical queries\n",
    "9. **Hybrid Agent** - Build an agent combining MCP tools, async tools, and multi-modal content\n",
    "10. **MCP Performance** - Compare MCP tools with equivalent custom Python implementations\n",
    "\n",
    "### Challenge:\n",
    "Build a document processing pipeline that:\n",
    "1. Downloads multiple files concurrently\n",
    "2. Processes them sequentially with progress updates\n",
    "3. Optionally uses MCP tools to enrich data\n",
    "4. Generates a summary report\n",
    "\n",
    "Use the cell below for your experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Success Criteria\n",
    "\n",
    "You've completed Lesson 5 if:\n",
    "\n",
    "- ‚úÖ Async tools stream progress in real-time via `yield`\n",
    "- ‚úÖ ConcurrentToolExecutor runs tools in parallel\n",
    "- ‚úÖ SequentialToolExecutor runs tools in order\n",
    "- ‚úÖ Async tools show measurable speedup vs sequential\n",
    "- ‚úÖ Stream events are properly formatted and received\n",
    "- ‚úÖ Agent processes images (PNG, JPEG) correctly\n",
    "- ‚úÖ Agent processes PDF documents correctly\n",
    "- ‚úÖ Multi-modal agents invoked with real receipt image and PDF\n",
    "- ‚úÖ Document analyzer and receipt extractor demonstrated\n",
    "- ‚úÖ MCP concepts understood (optional: run MCP examples if available)\n",
    "\n",
    "## üí° Key Concepts Learned\n",
    "\n",
    "- **Async Tools** - Use `async def` with `yield` for streaming progress\n",
    "- **Streaming** - `agent.stream_async()` for real-time event consumption\n",
    "- **ConcurrentToolExecutor** - Parallel execution for independent operations (1.4-1.5x speedup)\n",
    "- **SequentialToolExecutor** - Ordered execution for dependent operations\n",
    "- **Multi-modal** - Process images and PDFs directly in messages with Bedrock Converse format\n",
    "- **MCP Integration** - External tool integration via Model Context Protocol (optional)\n",
    "- **Context Managers** - Required pattern for MCP operations (`with mcp_client:`)\n",
    "- **Hybrid Agents** - Combining MCP tools with custom Python tools\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Lesson 6**: Hooks & Structured Output - Lifecycle hooks and Pydantic models\n",
    "- **Lesson 7**: Advanced Tools & Context - Class-based tools, ToolContext, conversation management\n",
    "\n",
    "Ready to continue? Open `lesson_06_hooks_structured.ipynb`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Strands)",
   "language": "python",
   "name": "strands-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
