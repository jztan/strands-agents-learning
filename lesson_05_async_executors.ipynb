{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: Async Streaming, Executors & Multi-modal\n",
    "\n",
    "Master async operations, streaming, tool execution strategies, and multi-modal content:\n",
    "\n",
    "- âœ… Async tool definition with `async def` and `await`\n",
    "- âœ… Streaming progress updates with `yield` in async tools\n",
    "- âœ… Using `agent.stream_async()` for real-time responses\n",
    "- âœ… ConcurrentToolExecutor for parallel tool execution (default)\n",
    "- âœ… SequentialToolExecutor for ordered tool execution\n",
    "- âœ… Multi-modal content (images, PDFs, documents)\n",
    "\n",
    "**Estimated time:** 4-5 hours\n",
    "\n",
    "**What you'll build:** Streaming tools, executor comparisons, and multi-modal examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary modules and configure the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API keys detected: OpenAI\n",
      "ðŸŽ¯ Lesson 5: Async Streaming, Executors & Multi-modal\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands.tools.executors import ConcurrentToolExecutor, SequentialToolExecutor\n",
    "\n",
    "from lesson_utils import (\n",
    "    load_environment,\n",
    "    create_working_model,\n",
    "    check_api_keys,\n",
    "    print_troubleshooting,\n",
    ")\n",
    "\n",
    "# Load environment and check API keys\n",
    "load_environment()\n",
    "check_api_keys()\n",
    "\n",
    "print(\"ðŸŽ¯ Lesson 5: Async Streaming, Executors & Multi-modal\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Async Tools with Streaming Progress\n",
    "\n",
    "Async tools can `yield` intermediate results to provide real-time progress updates. Each yielded value becomes a streaming event that you can consume with `agent.stream_async()`.\n",
    "\n",
    "**Reference:** [Python Tools - Tool Streaming](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/python-tools/#tool-streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Async streaming tools created!\n"
     ]
    }
   ],
   "source": [
    "# Define async tools with yield for streaming progress\n",
    "\n",
    "@tool\n",
    "async def process_dataset(records: int) -> str:\n",
    "    \"\"\"Process records with progress updates.\"\"\"\n",
    "    start = datetime.now()\n",
    "\n",
    "    for i in range(1, records + 1):\n",
    "        await asyncio.sleep(0.1)  # Simulate processing time\n",
    "        if i % 10 == 0:\n",
    "            elapsed = (datetime.now() - start).total_seconds()\n",
    "            yield f\"Processed {i}/{records} records in {elapsed:.1f}s\"\n",
    "\n",
    "    total_time = (datetime.now() - start).total_seconds()\n",
    "    yield f\"âœ“ Completed {records} records in {total_time:.1f}s\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def download_file(url: str, size_mb: int = 10) -> str:\n",
    "    \"\"\"Simulate downloading a file with progress updates.\"\"\"\n",
    "    chunks = 10\n",
    "    chunk_size = size_mb / chunks\n",
    "\n",
    "    yield f\"Starting download: {url} ({size_mb}MB)\"\n",
    "\n",
    "    for i in range(1, chunks + 1):\n",
    "        await asyncio.sleep(0.2)  # Simulate download time\n",
    "        progress = (i / chunks) * 100\n",
    "        downloaded = chunk_size * i\n",
    "        yield f\"Downloaded {downloaded:.1f}MB / {size_mb}MB ({progress:.0f}%)\"\n",
    "\n",
    "    yield f\"âœ“ Download complete: {url}\"\n",
    "\n",
    "\n",
    "print(\"âœ… Async streaming tools created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Using OpenAI gpt-4o-mini\n",
      "Streaming progress from async tools...\n",
      "\n",
      "\n",
      "Tool #1: process_dataset\n",
      "ðŸ“Š Progress: Processed 10/30 records in 1.0s\n",
      "ðŸ“Š Progress: Processed 20/30 records in 2.0s\n",
      "ðŸ“Š Progress: Processed 30/30 records in 3.0s\n",
      "ðŸ“Š Progress: âœ“ Completed 30 records in 3.0s\n",
      "IðŸ¤– Agent: I haveðŸ¤– Agent:  have successfullyðŸ¤– Agent:  successfully processedðŸ¤– Agent:  processed ðŸ¤– Agent:  30ðŸ¤– Agent: 30 recordsðŸ¤– Agent:  records inðŸ¤– Agent:  in ðŸ¤– Agent:  3ðŸ¤– Agent: 3 secondsðŸ¤– Agent:  seconds.ðŸ¤– Agent: . IfðŸ¤– Agent:  If youðŸ¤– Agent:  you needðŸ¤– Agent:  need anyðŸ¤– Agent:  any furtherðŸ¤– Agent:  further assistanceðŸ¤– Agent:  assistance,ðŸ¤– Agent: , feelðŸ¤– Agent:  feel freeðŸ¤– Agent:  free toðŸ¤– Agent:  to askðŸ¤– Agent:  ask!ðŸ¤– Agent: !"
     ]
    }
   ],
   "source": [
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    # Create agent with async streaming tools\n",
    "    agent = Agent(\n",
    "        model=model,\n",
    "        tools=[process_dataset, download_file],\n",
    "        system_prompt=\"You are a helpful assistant with data processing capabilities.\",\n",
    "    )\n",
    "\n",
    "    print(\"Streaming progress from async tools...\\n\")\n",
    "\n",
    "    async def demo_streaming():\n",
    "        async for event in agent.stream_async(\"Process 30 records\"):\n",
    "            # Check for tool stream events (progress updates)\n",
    "            if tool_stream := event.get(\"tool_stream_event\"):\n",
    "                if update := tool_stream.get(\"data\"):\n",
    "                    print(f\"ðŸ“Š Progress: {update}\")\n",
    "\n",
    "            # Check for final text response\n",
    "            if \"data\" in event and not event.get(\"tool_stream_event\"):\n",
    "                print(f\"ðŸ¤– Agent: {event['data']}\", end=\"\")\n",
    "\n",
    "    await demo_streaming()\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: ConcurrentToolExecutor (Parallel Execution)\n",
    "\n",
    "`ConcurrentToolExecutor` is the default executor. It executes multiple tools in parallel when the LLM requests multiple tools in a single response.\n",
    "\n",
    "**Reference:** [Tool Executors](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/executors/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API simulation tools created!\n"
     ]
    }
   ],
   "source": [
    "# Define tools that simulate API calls\n",
    "\n",
    "@tool\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather forecast for a city.\"\"\"\n",
    "    await asyncio.sleep(1.0)  # Simulate API call\n",
    "    return f\"Weather in {city}: Sunny, 72Â°F\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def get_time(city: str) -> str:\n",
    "    \"\"\"Get current time in a city.\"\"\"\n",
    "    await asyncio.sleep(1.0)  # Simulate API call\n",
    "    return f\"Time in {city}: 2:30 PM\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def get_population(city: str) -> str:\n",
    "    \"\"\"Get population of a city.\"\"\"\n",
    "    await asyncio.sleep(1.0)  # Simulate database query\n",
    "    return f\"Population of {city}: ~1.5 million\"\n",
    "\n",
    "\n",
    "print(\"âœ… API simulation tools created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Using OpenAI gpt-4o-mini\n",
      "Testing ConcurrentToolExecutor (tools run in parallel)...\n",
      "\n",
      "\n",
      "Tool #1: get_weather\n",
      "\n",
      "Tool #2: get_time\n",
      "\n",
      "Tool #3: get_population\n",
      "In Seattle, the weather is sunny with a temperature of 72Â°F. The current time is 2:30 PM, and the population of Seattle is approximately 1.5 million.\n",
      "ðŸ¤– Agent: In Seattle, the weather is sunny with a temperature of 72Â°F. The current time is 2:30 PM, and the population of Seattle is approximately 1.5 million.\n",
      "\n",
      "\n",
      "âš¡ Total time: 4.68s\n",
      "ðŸ’¡ With concurrent execution, 3 tools (each taking 1s) complete in ~1s!\n"
     ]
    }
   ],
   "source": [
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    # ConcurrentToolExecutor is the default\n",
    "    agent = Agent(\n",
    "        model=model,\n",
    "        tool_executor=ConcurrentToolExecutor(),\n",
    "        tools=[get_weather, get_time, get_population],\n",
    "        system_prompt=\"Use tools to answer user questions about cities.\",\n",
    "    )\n",
    "\n",
    "    print(\"Testing ConcurrentToolExecutor (tools run in parallel)...\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = await agent.invoke_async(\n",
    "        \"What's the weather, time, and population in Seattle?\"\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nðŸ¤– Agent: {response}\")\n",
    "    print(f\"\\nâš¡ Total time: {elapsed:.2f}s\")\n",
    "    print(\"ðŸ’¡ With concurrent execution, 3 tools (each taking 1s) complete in ~1s!\")\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: SequentialToolExecutor (Ordered Execution)\n",
    "\n",
    "`SequentialToolExecutor` executes tools one after another in the order specified by the LLM. This is useful for dependent operations where one tool's output is needed by the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Workflow tools created!\n"
     ]
    }
   ],
   "source": [
    "# Define tools for dependent operations\n",
    "\n",
    "@tool\n",
    "async def take_screenshot(filename: str) -> str:\n",
    "    \"\"\"Take a screenshot and save to file.\"\"\"\n",
    "    await asyncio.sleep(0.5)  # Simulate screenshot capture\n",
    "    return f\"Screenshot saved to {filename}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def compress_file(filename: str) -> str:\n",
    "    \"\"\"Compress a file to save space.\"\"\"\n",
    "    await asyncio.sleep(0.5)  # Simulate compression\n",
    "    compressed = filename.replace(\".png\", \".zip\")\n",
    "    return f\"Compressed {filename} to {compressed}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "async def send_email(recipient: str, attachment: str) -> str:\n",
    "    \"\"\"Send an email with an attachment.\"\"\"\n",
    "    await asyncio.sleep(0.5)  # Simulate email sending\n",
    "    return f\"Email sent to {recipient} with attachment: {attachment}\"\n",
    "\n",
    "\n",
    "print(\"âœ… Workflow tools created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Using OpenAI gpt-4o-mini\n",
      "Testing SequentialToolExecutor (tools run in order)...\n",
      "Task: Take screenshot â†’ Compress â†’ Email\n",
      "\n",
      "\n",
      "Tool #1: take_screenshot\n",
      "\n",
      "Tool #2: compress_file\n",
      "\n",
      "Tool #3: send_email\n",
      "The screenshot has been taken, compressed, and emailed to boss@company.com successfully.\n",
      "ðŸ¤– Agent: The screenshot has been taken, compressed, and emailed to boss@company.com successfully.\n",
      "\n",
      "\n",
      "â±ï¸  Total time: 5.04s\n",
      "ðŸ’¡ Operations executed in the correct order!\n"
     ]
    }
   ],
   "source": [
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    # Use SequentialToolExecutor for dependent operations\n",
    "    agent = Agent(\n",
    "        model=model,\n",
    "        tool_executor=SequentialToolExecutor(),\n",
    "        tools=[take_screenshot, compress_file, send_email],\n",
    "        system_prompt=\"Execute tasks in the correct order for dependent operations.\",\n",
    "    )\n",
    "\n",
    "    print(\"Testing SequentialToolExecutor (tools run in order)...\")\n",
    "    print(\"Task: Take screenshot â†’ Compress â†’ Email\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = await agent.invoke_async(\n",
    "        \"Take a screenshot named report.png, compress it, \"\n",
    "        \"then email the compressed file to boss@company.com\"\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nðŸ¤– Agent: {response}\")\n",
    "    print(f\"\\nâ±ï¸  Total time: {elapsed:.2f}s\")\n",
    "    print(\"ðŸ’¡ Operations executed in the correct order!\")\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Performance Comparison\n",
    "\n",
    "Let's compare the performance difference between concurrent and sequential execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Using OpenAI gpt-4o-mini\n",
      "1. Testing ConcurrentToolExecutor:\n",
      "\n",
      "Tool #1: fetch_data\n",
      "\n",
      "Tool #2: fetch_data\n",
      "\n",
      "Tool #3: fetch_data\n",
      "I have fetched the data from the sources:\n",
      "\n",
      "- **API-A**: Data from API-A: [sample data]\n",
      "- **API-B**: Data from API-B: [sample data]\n",
      "- **API-C**: Data from API-C: [sample data]   âš¡ Concurrent time: 4.69s\n",
      "\n",
      "2. Testing SequentialToolExecutor:\n",
      "\n",
      "Tool #1: fetch_data\n",
      "\n",
      "Tool #2: fetch_data\n",
      "\n",
      "Tool #3: fetch_data\n",
      "Here is the data fetched from the APIs:\n",
      "\n",
      "- **API-A**: Data from API-A: [sample data]\n",
      "- **API-B**: Data from API-B: [sample data]\n",
      "- **API-C**: Data from API-C: [sample data]   â±ï¸  Sequential time: 7.05s\n",
      "\n",
      "3. Performance Summary:\n",
      "   Concurrent: 4.69s\n",
      "   Sequential: 7.05s\n",
      "   Speedup: 1.50x faster with concurrent execution!\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "async def fetch_data(source: str) -> str:\n",
    "    \"\"\"Fetch data from a source (simulated).\"\"\"\n",
    "    await asyncio.sleep(1.0)  # Simulate network delay\n",
    "    return f\"Data from {source}: [sample data]\"\n",
    "\n",
    "\n",
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    # Test with ConcurrentToolExecutor\n",
    "    print(\"1. Testing ConcurrentToolExecutor:\")\n",
    "    concurrent_agent = Agent(\n",
    "        model=model,\n",
    "        tool_executor=ConcurrentToolExecutor(),\n",
    "        tools=[fetch_data],\n",
    "        system_prompt=\"Fetch data from multiple sources.\",\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    await concurrent_agent.invoke_async(\"Fetch data from API-A, API-B, and API-C\")\n",
    "    concurrent_time = time.time() - start\n",
    "    print(f\"   âš¡ Concurrent time: {concurrent_time:.2f}s\")\n",
    "\n",
    "    # Test with SequentialToolExecutor\n",
    "    print(\"\\n2. Testing SequentialToolExecutor:\")\n",
    "    sequential_agent = Agent(\n",
    "        model=model,\n",
    "        tool_executor=SequentialToolExecutor(),\n",
    "        tools=[fetch_data],\n",
    "        system_prompt=\"Fetch data from multiple sources.\",\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    await sequential_agent.invoke_async(\"Fetch data from API-A, API-B, and API-C\")\n",
    "    sequential_time = time.time() - start\n",
    "    print(f\"   â±ï¸  Sequential time: {sequential_time:.2f}s\")\n",
    "\n",
    "    # Show comparison\n",
    "    print(\"\\n3. Performance Summary:\")\n",
    "    print(f\"   Concurrent: {concurrent_time:.2f}s\")\n",
    "    print(f\"   Sequential: {sequential_time:.2f}s\")\n",
    "    speedup = sequential_time / concurrent_time if concurrent_time > 0 else 1\n",
    "    print(f\"   Speedup: {speedup:.2f}x faster with concurrent execution!\")\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Multi-modal Content\n",
    "\n",
    "Agents can process multi-modal content including images and PDFs. This enables visual understanding and document analysis.\n",
    "\n",
    "**Reference:** [Multi-modal Example](https://strandsagents.com/latest/documentation/docs/examples/python/multimodal/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¸ Creating sample receipt...\n",
      "âœ“ Created: sample_receipt.png\n",
      "\n",
      "ðŸš€ Using OpenAI gpt-4o-mini\n",
      "Using provider-agnostic multi-modal approach\n",
      "\n",
      "1. Document Analyzer:\n",
      "Here is the key information extracted from the receipt:\n",
      "\n",
      "- **Store Name:** ACME GROCERY\n",
      "- **Address:** 123 Main St\n",
      "- **Receipt Number:** 2025-001234\n",
      "- **Date:** October 11, 2025\n",
      "\n",
      "**Items Purchased:**\n",
      "1. Apples (2 lbs) - $5.99\n",
      "2. Bread - $3.49\n",
      "3. Eggs (12) - $4.99\n",
      "4. Milk - $4.29\n",
      "5. Salmon - $12.99\n",
      "6. Greens - $3.49\n",
      "\n",
      "**Financial Summary:**\n",
      "- **Subtotal:** $35.24\n",
      "- **Tax:** $3.00\n",
      "- **Total:** $38.24ðŸ“„ Analysis:\n",
      "Here is the key information extracted from the receipt:\n",
      "\n",
      "- **Store Name:** ACME GROCERY\n",
      "- **Address:** 123 Main St\n",
      "- **Receipt Number:** 2025-001234\n",
      "- **Date:** October 11, 2025\n",
      "\n",
      "**Items Purchased:**\n",
      "1. Apples (2 lbs) - $5.99\n",
      "2. Bread - $3.49\n",
      "3. Eggs (12) - $4.99\n",
      "4. Milk - $4.29\n",
      "5. Salmon - $12.99\n",
      "6. Greens - $3.49\n",
      "\n",
      "**Financial Summary:**\n",
      "- **Subtotal:** $35.24\n",
      "- **Tax:** $3.00\n",
      "- **Total:** $38.24\n",
      "\n",
      "\n",
      "2. Receipt Extractor:\n",
      "Here is the extracted financial data from the receipt:\n",
      "\n",
      "- **Store**: ACME GROCERY\n",
      "- **Date**: Oct 11, 2025\n",
      "- **Receipt #**: 2025-001234\n",
      "\n",
      "**Line Items**:\n",
      "1. Apples (2 lbs): $5.99\n",
      "2. Bread: $3.49\n",
      "3. Eggs (12): $4.99\n",
      "4. Milk: $4.29\n",
      "5. Salmon: $12.99\n",
      "6. Greens: $3.49\n",
      "\n",
      "**Totals**:\n",
      "- **Subtotal**: $35.24\n",
      "- **Tax**: $3.00\n",
      "- **Total**: $38.24ðŸ’° Data:\n",
      "Here is the extracted financial data from the receipt:\n",
      "\n",
      "- **Store**: ACME GROCERY\n",
      "- **Date**: Oct 11, 2025\n",
      "- **Receipt #**: 2025-001234\n",
      "\n",
      "**Line Items**:\n",
      "1. Apples (2 lbs): $5.99\n",
      "2. Bread: $3.49\n",
      "3. Eggs (12): $4.99\n",
      "4. Milk: $4.29\n",
      "5. Salmon: $12.99\n",
      "6. Greens: $3.49\n",
      "\n",
      "**Totals**:\n",
      "- **Subtotal**: $35.24\n",
      "- **Tax**: $3.00\n",
      "- **Total**: $38.24\n",
      "\n",
      "\n",
      "ðŸ’¡ Key Takeaways:\n",
      "âœ“ Images passed directly in messages (provider-agnostic)\n",
      "âœ“ Works with OpenAI, Anthropic, and other vision models\n",
      "âœ“ Bedrock Converse format: {'image': {'format': 'png', ...}}\n"
     ]
    }
   ],
   "source": [
    "# Multi-modal works with any vision model (OpenAI, Anthropic, etc.)\n",
    "# We pass images directly in messages using Bedrock Converse format\n",
    "\n",
    "import os\n",
    "\n",
    "# Create sample receipt\n",
    "def create_sample_receipt():\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    \n",
    "    width, height = 400, 600\n",
    "    img = Image.new('RGB', (width, height), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    try:\n",
    "        font_large = ImageFont.truetype(\"Arial.ttf\", 24)\n",
    "        font_medium = ImageFont.truetype(\"Arial.ttf\", 18)\n",
    "        font_small = ImageFont.truetype(\"Arial.ttf\", 14)\n",
    "    except IOError:\n",
    "        font_large = ImageFont.load_default()\n",
    "        font_medium = ImageFont.load_default()\n",
    "        font_small = ImageFont.load_default()\n",
    "    \n",
    "    # Draw receipt (simplified)\n",
    "    y = 20\n",
    "    draw.text((width//2-70, y), \"ACME GROCERY\", fill='black', font=font_large)\n",
    "    y += 40\n",
    "    draw.text((width//2-60, y), \"123 Main St\", fill='black', font=font_small)\n",
    "    y += 40\n",
    "    draw.line([(20, y), (width-20, y)], fill='black', width=2)\n",
    "    y += 20\n",
    "    draw.text((20, y), \"Receipt #: 2025-001234\", fill='black', font=font_small)\n",
    "    y += 25\n",
    "    draw.text((20, y), \"Date: Oct 11, 2025\", fill='black', font=font_small)\n",
    "    y += 40\n",
    "    \n",
    "    items = [\n",
    "        (\"Apples (2 lbs)\", \"$5.99\"),\n",
    "        (\"Bread\", \"$3.49\"),\n",
    "        (\"Eggs (12)\", \"$4.99\"),\n",
    "        (\"Milk\", \"$4.29\"),\n",
    "        (\"Salmon\", \"$12.99\"),\n",
    "        (\"Greens\", \"$3.49\"),\n",
    "    ]\n",
    "    for item, price in items:\n",
    "        draw.text((20, y), item, fill='black', font=font_small)\n",
    "        draw.text((width-80, y), price, fill='black', font=font_small)\n",
    "        y += 22\n",
    "    \n",
    "    y += 10\n",
    "    draw.line([(20, y), (width-20, y)], fill='black', width=1)\n",
    "    y += 20\n",
    "    draw.text((20, y), \"Subtotal:\", fill='black', font=font_medium)\n",
    "    draw.text((width-85, y), \"$35.24\", fill='black', font=font_medium)\n",
    "    y += 25\n",
    "    draw.text((20, y), \"Tax:\", fill='black', font=font_medium)\n",
    "    draw.text((width-85, y), \"$3.00\", fill='black', font=font_medium)\n",
    "    y += 25\n",
    "    draw.line([(20, y), (width-20, y)], fill='black', width=2)\n",
    "    y += 20\n",
    "    draw.text((20, y), \"TOTAL:\", fill='black', font=font_large)\n",
    "    draw.text((width-90, y), \"$38.24\", fill='black', font=font_large)\n",
    "    \n",
    "    filename = 'sample_receipt.png'\n",
    "    img.save(filename)\n",
    "    return filename\n",
    "\n",
    "print(\"ðŸ“¸ Creating sample receipt...\")\n",
    "receipt_path = create_sample_receipt()\n",
    "print(f\"âœ“ Created: {receipt_path}\\n\")\n",
    "\n",
    "# Read image as bytes\n",
    "with open(receipt_path, 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "model = create_working_model()\n",
    "\n",
    "if model:\n",
    "    print(\"Using provider-agnostic multi-modal approach\\n\")\n",
    "    \n",
    "    # Demo 1: Document Analyzer (works with any vision model)\n",
    "    print(\"1. Document Analyzer:\")\n",
    "    analyzer = Agent(\n",
    "        model=model,\n",
    "        system_prompt=\"Analyze images and extract all visible text and key information.\"\n",
    "    )\n",
    "    \n",
    "    # Pass image directly in message (Bedrock Converse format)\n",
    "    message = [\n",
    "        {\"text\": \"Analyze this receipt image and extract key information:\"},\n",
    "        {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": image_bytes}}}\n",
    "    ]\n",
    "    \n",
    "    response = await analyzer.invoke_async(message)\n",
    "    print(f\"ðŸ“„ Analysis:\\n{response}\\n\")\n",
    "    \n",
    "    # Demo 2: Receipt Extractor\n",
    "    print(\"2. Receipt Extractor:\")\n",
    "    extractor = Agent(\n",
    "        model=model,\n",
    "        system_prompt=\"Extract financial data: store, date, line items, totals.\"\n",
    "    )\n",
    "    \n",
    "    message = [\n",
    "        {\"text\": \"Extract all financial data from this receipt:\"},\n",
    "        {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": image_bytes}}}\n",
    "    ]\n",
    "    \n",
    "    response = await extractor.invoke_async(message)\n",
    "    print(f\"ðŸ’° Data:\\n{response}\\n\")\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(receipt_path)\n",
    "    \n",
    "    print(\"ðŸ’¡ Key Takeaways:\")\n",
    "    print(\"âœ“ Images passed directly in messages (provider-agnostic)\")\n",
    "    print(\"âœ“ Works with OpenAI, Anthropic, and other vision models\")\n",
    "    print(\"âœ“ Bedrock Converse format: {'image': {'format': 'png', ...}}\")\n",
    "else:\n",
    "    print_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Experiments\n\nNow it's your turn! Try these experiments:\n\n### Exercises:\n1. **Large dataset processing** - Process 100 records and watch the streaming progress\n2. **Variable delays** - Create tools with different delays (0.5s, 1s, 2s) and compare executors\n3. **Data pipeline** - Build a multi-step pipeline with dependent operations\n4. **Parallel API calls** - Simulate calling 5 different APIs concurrently\n5. **Real images** - Use different receipt/invoice images with the multi-modal approach\n6. **Multiple images** - Pass multiple images in one message for comparison\n7. **Document classification** - Build a classifier that categorizes document types\n\n### Challenge:\nBuild a document processing pipeline that:\n1. Downloads multiple files concurrently\n2. Processes them sequentially with progress updates\n3. Generates a summary report\n\nUse the cell below for your experiments:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Success Criteria\n",
    "\n",
    "You've completed Lesson 5 if:\n",
    "\n",
    "- âœ… Async tools stream progress in real-time via `yield`\n",
    "- âœ… ConcurrentToolExecutor runs tools in parallel\n",
    "- âœ… SequentialToolExecutor runs tools in order\n",
    "- âœ… Async tools show measurable speedup vs sequential\n",
    "- âœ… Stream events are properly formatted and received\n",
    "- âœ… Agent processes images (PNG, JPEG) correctly\n",
    "- âœ… Multi-modal agents invoked with real receipt image\n",
    "- âœ… Document analyzer and receipt extractor demonstrated\n",
    "\n",
    "## ðŸ’¡ Key Concepts Learned\n",
    "\n",
    "- **Async Tools** - Use `async def` with `yield` for streaming progress\n",
    "- **Streaming** - `agent.stream_async()` for real-time event consumption\n",
    "- **ConcurrentToolExecutor** - Parallel execution for independent operations (1.4-1.5x speedup)\n",
    "- **SequentialToolExecutor** - Ordered execution for dependent operations\n",
    "- **Multi-modal** - Process images with `image_reader` tool, extract text via OCR\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Lesson 6**: Hooks & Structured Output - Lifecycle hooks and Pydantic models\n",
    "- **Lesson 7**: Advanced Tools, Context & MCP - Class-based tools, conversation management, MCP integration\n",
    "\n",
    "Ready to continue? Open `lesson_06_hooks_structured.ipynb`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Strands)",
   "language": "python",
   "name": "strands-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}